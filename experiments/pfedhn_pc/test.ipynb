{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import random\n",
    "from collections import defaultdict, OrderedDict\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import experiments\n",
    "import model\n",
    "from experiments.pfedhn_pc.utils import get_average_model, weighted_aggregate_model\n",
    "from tqdm import trange\n",
    "\n",
    "from experiments.pfedhn_pc.models import CNNHyperPC, CNNTargetPC, CNNTargetPC_M, LocalLayer\n",
    "from experiments.pfedhn_pc.node import BaseNodesForLocal, BaseNodesForLocals_M\n",
    "from experiments.utils import get_device, set_logger, set_seed, str2bool\n",
    "\n",
    "import copy\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "imp.reload(experiments)\n",
    "imp.reload(model)\n",
    "from model import *\n",
    "from experiments.pfedhn_pc.utils import get_average_model, weighted_aggregate_model\n",
    "from experiments.pfedhn_pc.node import BaseNodesForLocal, BaseNodesForLocals_M\n",
    "from experiments.utils import get_device, set_logger, set_seed, str2bool\n",
    "from experiments.pfedhn_pc.models import CNNHyperPC, CNNTargetPC, CNNTargetPC_M, LocalLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'cifar10'\n",
    "\n",
    "if data_name == 'cifar10':\n",
    "    classes_per_node = 2\n",
    "else:\n",
    "    classes_per_node = 10\n",
    "\n",
    "data_path = 'data'\n",
    "num_nodes = 50\n",
    "num_steps = 5000\n",
    "inner_steps = 50\n",
    "optim = 'sgd'\n",
    "lr = 5e-2\n",
    "inner_lr = 5e-3 \n",
    "embed_lr = None\n",
    "wd = 1e-3\n",
    "inner_wd = 5e-5\n",
    "embed_dim = -1\n",
    "batch_size = 64\n",
    "eval_every = 30\n",
    "save_path = \"pfedhn_pc_cifar_res\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BaseNodesForLocals_M' object has no attribute 'local_layers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_324416/3781443557.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mclasses_per_node\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclasses_per_node\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m )\n",
      "\u001b[1;32mc:\\users\\fang\\documents\\gitspace\\pfedhn-fedtrans\\experiments\\pfedhn_pc\\node.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data_name, data_path, n_nodes, base_model, layer_config, base_optimizer, optimizer_config, device, batch_size, classes_per_node)\u001b[0m\n\u001b[0;32m     66\u001b[0m         ]\n\u001b[0;32m     67\u001b[0m         self.local_optimizers = [\n\u001b[1;32m---> 68\u001b[1;33m             \u001b[0mbase_optimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptimizer_config\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_nodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m         ]\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\fang\\documents\\gitspace\\pfedhn-fedtrans\\experiments\\pfedhn_pc\\node.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     66\u001b[0m         ]\n\u001b[0;32m     67\u001b[0m         self.local_optimizers = [\n\u001b[1;32m---> 68\u001b[1;33m             \u001b[0mbase_optimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptimizer_config\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_nodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m         ]\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'BaseNodesForLocals_M' object has no attribute 'local_layers'"
     ]
    }
   ],
   "source": [
    "\n",
    "nodes = BaseNodesForLocals_M(\n",
    "    data_name=data_name,\n",
    "    data_path=data_path,\n",
    "    n_nodes=num_nodes,\n",
    "    base_model=CNNTargetPC_M,\n",
    "    layer_config={'in_channels':3},\n",
    "    base_optimizer=torch.optim.SGD, optimizer_config=dict(lr=inner_lr, momentum=.9, weight_decay=inner_wd),\n",
    "    device=device,\n",
    "    batch_size=batch_size,\n",
    "    classes_per_node=classes_per_node,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                              | 0/5000 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "embed_dim = embed_dim    \n",
    "if embed_dim == -1:\n",
    "    logging.info(\"auto embedding size\")\n",
    "    embed_dim = int(1 + num_nodes / 4)\n",
    "\n",
    "inet = CNNTargetPC_M()\n",
    "#net = CNNTargetPC(n_kernels=n_kernels)\n",
    "\n",
    "inet = inet.to(device)\n",
    "#net = net.to(device)#unnecessary\n",
    "\n",
    "##################\n",
    "# init optimizer #\n",
    "##################\n",
    "embed_lr = embed_lr if embed_lr is not None else lr\n",
    "optimizers = {\n",
    "    'sgd': torch.optim.SGD(\n",
    "        [\n",
    "            {'params': [p for n, p in inet.named_parameters() if 'embed' not in n]},\n",
    "            {'params': [p for n, p in inet.named_parameters() if 'embed' in n], 'lr': embed_lr}\n",
    "        ], lr=lr, momentum=0.9, weight_decay=wd\n",
    "    ),\n",
    "    'adam': torch.optim.Adam(params=inet.parameters(), lr=lr)\n",
    "}\n",
    "optimizer = optimizers[optim]\n",
    "criteria = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "################\n",
    "# init metrics #\n",
    "################\n",
    "last_eval = -1\n",
    "best_step = -1\n",
    "best_acc = -1\n",
    "test_best_based_on_step, test_best_min_based_on_step = -1, -1\n",
    "test_best_max_based_on_step, test_best_std_based_on_step = -1, -1\n",
    "step_iter = trange(num_steps)\n",
    "\n",
    "results = defaultdict(list)\n",
    "\n",
    "net_keys = [*inet.state_dict().keys()]\n",
    "base_layer_keys = net_keys[:-2]\n",
    "per_layer_keys = net_keys[-2:]\n",
    "\n",
    "net_values = [*inet.state_dict().values()]\n",
    "base_values = net_values[:-2]\n",
    "per_values = net_values[-2:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = Server(base_values, client_list=nodes.models, num_client=100, \n",
    "                pre_update_eps=100, per_layer=per_values, num_cluster=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(nodes, num_nodes, inet, net, criteria, device, split):\n",
    "    curr_results = evaluate(nodes, num_nodes, inet, net, criteria, device, split=split)\n",
    "    total_correct = sum([val['correct'] for val in curr_results.values()])\n",
    "    total_samples = sum([val['total'] for val in curr_results.values()])\n",
    "    avg_loss = np.mean([val['loss'] for val in curr_results.values()])\n",
    "    avg_acc = total_correct / total_samples\n",
    "\n",
    "    all_acc = [val['correct'] / val['total'] for val in curr_results.values()]\n",
    "\n",
    "    return curr_results, avg_loss, avg_acc, all_acc\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(nodes: BaseNodesForLocal, num_nodes, inet, net, criteria, device, split='test'):\n",
    "    inet.eval()\n",
    "    results = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "    for node_id in range(num_nodes):  # iterating over nodes\n",
    "\n",
    "        running_loss, running_correct, running_samples = 0., 0., 0.\n",
    "        if split == 'test':\n",
    "            curr_data = nodes.test_loaders[node_id]\n",
    "        elif split == 'val':\n",
    "            curr_data = nodes.val_loaders[node_id]\n",
    "        else:\n",
    "            curr_data = nodes.train_loaders[node_id]\n",
    "\n",
    "        weights = inet(torch.tensor([node_id], dtype=torch.long).to(device))\n",
    "        net.load_state_dict(weights)\n",
    "\n",
    "        for batch_count, batch in enumerate(curr_data):\n",
    "            img, label = tuple(t.to(device) for t in batch)\n",
    "            net_out = net(img)\n",
    "            pred = nodes.local_layers[node_id](net_out)\n",
    "            running_loss += criteria(pred, label).item()\n",
    "            running_correct += pred.argmax(1).eq(label).sum().item()\n",
    "            running_samples += len(label)\n",
    "\n",
    "        results[node_id]['loss'] = running_loss / (batch_count + 1)\n",
    "        results[node_id]['correct'] = running_correct\n",
    "        results[node_id]['total'] = running_samples\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BaseNodesForLocals_M' object has no attribute 'net'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_380028/2015228341.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# each client load global weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mnodes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient_load_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;31m# select client at random\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mnode_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_nodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\fang\\documents\\gitspace\\pfedhn-fedtrans\\experiments\\pfedhn_pc\\node.py\u001b[0m in \u001b[0;36mclient_load_weights\u001b[1;34m(self, model_dict)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclient_load_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m             \u001b[0mn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'BaseNodesForLocals_M' object has no attribute 'net'"
     ]
    }
   ],
   "source": [
    "for step in step_iter:\n",
    "    inet.train()\n",
    "\n",
    "    # each client load global weights\n",
    "    nodes.client_load_weights(inet)\n",
    "    # select client at random\n",
    "    node_id = random.choice(range(num_nodes))\n",
    "\n",
    "    # NOTE: evaluation on sent model\n",
    "    with torch.no_grad():\n",
    "        for n in nodes.models:\n",
    "            n.eval()\n",
    "        inet.eval()\n",
    "        batch = next(iter(nodes.test_loaders[node_id]))\n",
    "        img, label = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        pred = nodes.model[node_id](img)\n",
    "\n",
    "        prvs_loss = criteria(pred, label)\n",
    "        prvs_acc = pred.argmax(1).eq(label).sum().item() / len(label)\n",
    "        inet.train()\n",
    "\n",
    "    # inner updates -> obtaining theta_tilda\n",
    "    for i in range(inner_steps):\n",
    "        for n in nodes.model:\n",
    "            n.train()\n",
    "        nodes.local_optimizers[node_id].zero_grad()\n",
    "\n",
    "        batch = next(iter(nodes.train_loaders[node_id]))\n",
    "        img, label = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        pred = nodes.models[node_id](img)\n",
    "\n",
    "        loss = criteria(pred, label)\n",
    "        loss.backward()\n",
    "\n",
    "        nodes.local_optimizers[node_id].step()\n",
    "\n",
    "    for w_local in nodes.models:\n",
    "        if w_glob is None:\n",
    "            w_glob = copy.deepcopy(w_local)\n",
    "        else:\n",
    "            for k in w_glob.keys():\n",
    "                w_glob[k] += w_local[k]\n",
    "\n",
    "    inet.load_state_dict(w_glob)\n",
    "\n",
    "\n",
    "    step_iter.set_description(\n",
    "        f\"Step: {step+1}, Node ID: {node_id}, Loss: {prvs_loss:.4f},  Acc: {prvs_acc:.4f}\"\n",
    "    )\n",
    "\n",
    "    if step % eval_every == 0:\n",
    "        last_eval = step\n",
    "        step_results, avg_loss, avg_acc, all_acc = eval_model(\n",
    "            nodes, num_nodes, inet, net, criteria, device, split=\"test\"\n",
    "        )\n",
    "        logging.info(f\"\\nStep: {step+1}, AVG Loss: {avg_loss:.4f},  AVG Acc: {avg_acc:.4f}\")\n",
    "\n",
    "        results['test_avg_loss'].append(avg_loss)\n",
    "        results['test_avg_acc'].append(avg_acc)\n",
    "\n",
    "        _, val_avg_loss, val_avg_acc, _ = eval_model(nodes, num_nodes, inet, net, criteria, device, split=\"val\")\n",
    "        if best_acc < val_avg_acc:\n",
    "            best_acc = val_avg_acc\n",
    "            best_step = step\n",
    "            test_best_based_on_step = avg_acc\n",
    "            test_best_min_based_on_step = np.min(all_acc)\n",
    "            test_best_max_based_on_step = np.max(all_acc)\n",
    "            test_best_std_based_on_step = np.std(all_acc)\n",
    "\n",
    "        results['val_avg_loss'].append(val_avg_loss)\n",
    "        results['val_avg_acc'].append(val_avg_acc)\n",
    "        results['best_step'].append(best_step)\n",
    "        results['best_val_acc'].append(best_acc)\n",
    "        results['best_test_acc_based_on_val_beststep'].append(test_best_based_on_step)\n",
    "        results['test_best_min_based_on_step'].append(test_best_min_based_on_step)\n",
    "        results['test_best_max_based_on_step'].append(test_best_max_based_on_step)\n",
    "        results['test_best_std_based_on_step'].append(test_best_std_based_on_step)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if step != last_eval:\n",
    "    _, val_avg_loss, val_avg_acc, _ = eval_model(nodes, num_nodes, inet, net, criteria, device, split=\"val\")\n",
    "    step_results, avg_loss, avg_acc, all_acc = eval_model(nodes, num_nodes, inet, net, criteria, device, split=\"test\")\n",
    "    logging.info(f\"\\nStep: {step + 1}, AVG Loss: {avg_loss:.4f},  AVG Acc: {avg_acc:.4f}\")\n",
    "\n",
    "    results['test_avg_loss'].append(avg_loss)\n",
    "    results['test_avg_acc'].append(avg_acc)\n",
    "\n",
    "    if best_acc < val_avg_acc:\n",
    "        best_acc = val_avg_acc\n",
    "        best_step = step\n",
    "        test_best_based_on_step = avg_acc\n",
    "        test_best_min_based_on_step = np.min(all_acc)\n",
    "        test_best_max_based_on_step = np.max(all_acc)\n",
    "        test_best_std_based_on_step = np.std(all_acc)\n",
    "\n",
    "    results['val_avg_loss'].append(val_avg_loss)\n",
    "    results['val_avg_acc'].append(val_avg_acc)\n",
    "    results['best_step'].append(best_step)\n",
    "    results['best_val_acc'].append(best_acc)\n",
    "    results['best_test_acc_based_on_val_beststep'].append(test_best_based_on_step)\n",
    "    results['test_best_min_based_on_step'].append(test_best_min_based_on_step)\n",
    "    results['test_best_max_based_on_step'].append(test_best_max_based_on_step)\n",
    "    results['test_best_std_based_on_step'].append(test_best_std_based_on_step)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "293539041be06dcdbc1dd82d46367ecf96c14410c0014bf8043197a4a2571a26"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
