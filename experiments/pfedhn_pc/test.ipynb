{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import random\n",
    "from collections import defaultdict, OrderedDict\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from experiments.pfedhn_pc.utils import get_average_model, weighted_aggregate_model\n",
    "# from tqdm import trange\n",
    "\n",
    "from experiments.pfedhn_pc.models import CNNHyperPC, CNNTargetPC, CNNTargetPC_M, LocalLayer\n",
    "from experiments.pfedhn_pc.node import BaseNodesForLocal, BaseNodesForLocals_M\n",
    "from experiments.utils import get_device, set_logger, set_seed, str2bool\n",
    "\n",
    "import copy\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_317040/3759357367.py, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\fang\\AppData\\Local\\Temp/ipykernel_317040/3759357367.py\"\u001b[1;36m, line \u001b[1;32m14\u001b[0m\n\u001b[1;33m    batch_size =\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "data_name = 'cifar10'\n",
    "data_path = 'data'\n",
    "num_nodes = 50\n",
    "num_steps = 5000\n",
    "inner_steps = 50\n",
    "optim = 'sgd'\n",
    "lr = 5e-2\n",
    "inner_lr = 5e-3 \n",
    "embed_lr = None\n",
    "wd = 1e-3\n",
    "inner_wd = 5e-5\n",
    "embed_dim = -1\n",
    "batch_size = \n",
    "eval_every = \n",
    "save_path = \n",
    "\n",
    "args = {\n",
    "    'data_name' = \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(nodes, num_nodes, inet, net, criteria, device, split):\n",
    "    curr_results = evaluate(nodes, num_nodes, inet, net, criteria, device, split=split)\n",
    "    total_correct = sum([val['correct'] for val in curr_results.values()])\n",
    "    total_samples = sum([val['total'] for val in curr_results.values()])\n",
    "    avg_loss = np.mean([val['loss'] for val in curr_results.values()])\n",
    "    avg_acc = total_correct / total_samples\n",
    "\n",
    "    all_acc = [val['correct'] / val['total'] for val in curr_results.values()]\n",
    "\n",
    "    return curr_results, avg_loss, avg_acc, all_acc\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(nodes: BaseNodesForLocal, num_nodes, inet, net, criteria, device, split='test'):\n",
    "    inet.eval()\n",
    "    results = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "    for node_id in range(num_nodes):  # iterating over nodes\n",
    "\n",
    "        running_loss, running_correct, running_samples = 0., 0., 0.\n",
    "        if split == 'test':\n",
    "            curr_data = nodes.test_loaders[node_id]\n",
    "        elif split == 'val':\n",
    "            curr_data = nodes.val_loaders[node_id]\n",
    "        else:\n",
    "            curr_data = nodes.train_loaders[node_id]\n",
    "\n",
    "        weights = inet(torch.tensor([node_id], dtype=torch.long).to(device))\n",
    "        net.load_state_dict(weights)\n",
    "\n",
    "        for batch_count, batch in enumerate(curr_data):\n",
    "            img, label = tuple(t.to(device) for t in batch)\n",
    "            net_out = net(img)\n",
    "            pred = nodes.local_layers[node_id](net_out)\n",
    "            running_loss += criteria(pred, label).item()\n",
    "            running_correct += pred.argmax(1).eq(label).sum().item()\n",
    "            running_samples += len(label)\n",
    "\n",
    "        results[node_id]['loss'] = running_loss / (batch_count + 1)\n",
    "        results[node_id]['correct'] = running_correct\n",
    "        results[node_id]['total'] = running_samples\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "293539041be06dcdbc1dd82d46367ecf96c14410c0014bf8043197a4a2571a26"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('d2l')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
